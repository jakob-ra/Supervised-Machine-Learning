colnames(imdb)
sapply(imdb,class) # Checking classes of predictors
summary(is.na(imdb)) #NA's - quite many in gross_2015 budget, gross, budgeT_2015
# Selecting relevant subset
df_imdb <- imdb[!is.na(imdb$budget_2015),]
df_imdb <- df_imdb[!is.na(df_imdb$gross_2015),] # Remove obs with missing values
df_imdb <- df_imdb[(df_imdb[,15]>=1000000),]# Select movies only budget at least 1m
dropvars = c('imbd_score','gross','budget','user_reviews','critic_reviews','director','actors',)
dropvars = c('imbd_score','gross','budget','user_reviews','critic_reviews','director','actors')
colnames(df_imdb)
colnames(df_imdb)%in%dropvars
dropind = colnames(df_imdb)%in%dropvars
sum(dropind)
dropvars = c('imbd_score','gross','budget','user_reviews','critic_reviews','director','actors')
dropind = colnames(df_imdb)%in%dropvars
colnames(df_imdb)[dropind]
dropvars = c('imdb_score','gross','budget','user_reviews','critic_reviews','director','actors')
dropind = colnames(df_imdb)%in%dropvars
df_imdb <- df_imdb[,-dropind]# Select movies only budget at least 1m
#data_url <- "https://github.com/jakob-ra/Supervised-Machine-Learning/blob/master/HW5/imdb.RData"
load('imdb.RData')
#!!!! why / how set wd to git? to load data work
# Orig dataset
colnames(imdb)
sapply(imdb,class) # Checking classes of predictors
summary(is.na(imdb)) #NA's - quite many in gross_2015 budget, gross, budgeT_2015
# Selecting relevant subset
df_imdb <- imdb[!is.na(imdb$budget_2015),]
df_imdb <- df_imdb[!is.na(df_imdb$gross_2015),] # Remove obs with missing values
df_imdb <- df_imdb[(df_imdb[,15]>=1000000),]# Select movies only budget at least 1m
dropvars = c('imdb_score','gross','budget','user_reviews','critic_reviews','director','actors')
dropind = colnames(df_imdb)%in%dropvars
df_imdb <- df_imdb[,-dropind]# Select movies only budget at least 1m
load('imdb.RData')
#!!!! why / how set wd to git? to load data work
# Orig dataset
colnames(imdb)
sapply(imdb,class) # Checking classes of predictors
summary(is.na(imdb)) #NA's - quite many in gross_2015 budget, gross, budgeT_2015
# Selecting relevant subset
df_imdb <- imdb[!is.na(imdb$budget_2015),]
df_imdb <- df_imdb[!is.na(df_imdb$gross_2015),] # Remove obs with missing values
df_imdb <- df_imdb[(df_imdb[,15]>=1000000),]# Select movies only budget at least 1m
dropvars = c('imdb_score','gross','budget','user_reviews','critic_reviews','director','actors')
dropind = colnames(df_imdb)%in%dropvars
df_imdb <- df_imdb[,!dropind]# Select movies only budget at least 1m
#data_url <- "https://github.com/jakob-ra/Supervised-Machine-Learning/blob/master/HW5/imdb.RData"
load('imdb.RData')
#!!!! why / how set wd to git? to load data work
# Orig dataset
colnames(imdb)
sapply(imdb,class) # Checking classes of predictors
summary(is.na(imdb)) #NA's - quite many in gross_2015 budget, gross, budgeT_2015
# Selecting relevant subset
df_imdb <- imdb[!is.na(imdb$budget_2015),]
df_imdb <- df_imdb[!is.na(df_imdb$gross_2015),] # Remove obs with missing values
df_imdb <- df_imdb[(df_imdb[,15]>=1000000),]# Select movies only budget at least 1m
dropvars = c('imdb_score','gross','budget','user_reviews','critic_reviews','director','actors')
dropind = colnames(df_imdb)%in%dropvars
df_imdb <- df_imdb[,!dropind]# Select movies only budget at least 1m
# drop actor etc
# Make use of title: title length
df_imdb$title_length <- as.numeric(nchar(as.character(df_imdb$title)))
df_imdb$gross_x3 <- as.factor(df_imdb$gross_2015 >= (df_imdb$budget_2015)*3) # 1 = movies gross box office takings of at least three times its budget
#data_url <- "https://github.com/jakob-ra/Supervised-Machine-Learning/blob/master/HW5/imdb.RData"
load('imdb.RData')
#!!!! why / how set wd to git? to load data work
# Orig dataset
colnames(imdb)
sapply(imdb,class) # Checking classes of predictors
summary(is.na(imdb)) #NA's - quite many in gross_2015 budget, gross, budgeT_2015
# Selecting relevant subset
df_imdb <- imdb[!is.na(imdb$budget_2015),]
df_imdb <- df_imdb[!is.na(df_imdb$gross_2015),] # Remove obs with missing values
df_imdb <- df_imdb[(df_imdb[,15]>=1000000),]# Select movies only budget at least 1m
# Make use of title: title length
df_imdb$title_length <- as.numeric(nchar(as.character(df_imdb$title)))
titles = df_imdb$title
dropvars = c('imdb_score','gross','budget','user_reviews','critic_reviews','director','actors','title')
dropind = colnames(df_imdb)%in%dropvars
df_imdb <- df_imdb[,!dropind]# Select movies only budget at least 1m
# outcome
df_imdb$gross_x3 <- as.factor(df_imdb$gross_2015 >= (df_imdb$budget_2015)*3) #
# TEST #
# Supervised Machine Learning - HW5 - #
# Maja Nordfeldt, Feb 2020 #
# -------------------------- Packages ---------------------------#
# rm(list = ls())
library(tidyverse)
library(partykit)
library(randomForest)
library("rpart")
library("rpart.plot")
library(xtable)
# install.packages("multcomp")
# install.packages("party")
# install.packages('mvtnorm', dep = TRUE)
# install.packages("tidyverse", dep = TRUE)
# install.packages("rpart", dep = TRUE)
# install.packages("rpart.plot", dep = TRUE)
# install.packages("partykit", dep = TRUE)
# install.packages("kernlab", dep = TRUE)
# -------------------------- Data Preparation --------------------#
githubURL = "https://github.com/jakob-ra/Supervised-Machine-Learning/raw/master/HW5/imdb.RData"
load(url(githubURL))
#!!!! why / how set wd to git? to load data work
# Orig dataset
colnames(imdb)
sapply(imdb,class) # Checking classes of predictors
# Selecting relevant subset
df_imdb <- imdb[!is.na(imdb$budget_2015),] # drop missing budget
df_imdb <- df_imdb[!is.na(df_imdb$mpaa_rating),] # drop missing MPAA
df_imdb <- df_imdb[!is.na(df_imdb$gross_2015),] # Remove obs with missing values
df_imdb <- df_imdb[(df_imdb[,15]>=1000000),]# Select movies only budget at least 1m
# Make use of title: title length
df_imdb$title_length <- as.numeric(nchar(as.character(df_imdb$title)))
titles = df_imdb$title
# drop post screen variables
dropvars = c('imdb_score','gross', 'budget','user_reviews','critic_reviews','director','actors','title','year')
dropind = colnames(df_imdb)%in%dropvars
df_imdb <- df_imdb[,!dropind] # dropping
# create factor out of genre dummies
# outcome
df_imdb$gross_x3 <- as.factor(df_imdb$gross_2015 >= (df_imdb$budget_2015)*3) # 1 = movies gross box office takings of at least three times its budget
# Plot budget vs revenue, line with slope 3
plot(df_imdb$budget_2015,df_imdb$gross_2015)
abline(a=0,b=3)
plot(log(df_imdb$budget_2015),log(df_imdb$gross_2015))
abline(a=log(3),b=0)
df_imdb = subset(df_imdb, select = -gross_2015) # drop gross asa  predictor
# Missing values
summary(is.na(df_imdb))
# Analyse data imbalance
summary(df_imdb$gross_x3)
# ------------------ Package results for reference --------------------#
# small tree for visual explanation
treesmall = rpart(gross_x3 ~ . - gross_x3 -mpaa_rating,
control = rpart.control(minsplit =5, minbucket = 5,xval=5,cp = 0.004,maxdepth = 3),
data=df_imdb, method="class")
plot(as.party(treesmall))
# Single tree - cp = 1e-7 to get nice cp plot
set.seed(1)
tree = rpart(gross_x3 ~ . - gross_x3, control = rpart.control(minsplit =5, minbucket = 5,xval=10,cp = 1e-7,maxdepth = 10), data=df_imdb, method="class")
plotcp(tree)# 	plot cross-validation results
cpprint = printcp(tree)
cvmin = cpprint[which.min(cpprint[,4]),1]
cat('best cp:',cvmin,'\n')
cat('min xerror =:',cpprint[which.min(cpprint[,4]),4],'\n')
# Single tree - cp = 0.006 --> cross validated parameter
set.seed(1)
tree = rpart(gross_x3 ~ . - gross_x3,
control = rpart.control(minsplit =5, minbucket = 5,xval=5,cp = cvmin,maxdepth = 10),
data=df_imdb, method="class")
pred = predict(tree, type="class")
tree.conf = table(pred, df_imdb$gross_x3)
tree.conf.error = c(tree.conf[1,2]/(tree.conf[1,1]+tree.conf[1,2]),tree.conf[2,1]/(tree.conf[2,1]+tree.conf[2,2]))
tree.conf = cbind(tree.conf,tree.conf.error) # attach confusion error
colnames(tree.conf)[3] = 'class.error'
knitr::kable(tree.conf)
# plot the tree
plot(as.party(tree))
set.seed(1)
tree = rpart(gross_x3 ~ . - gross_x3,
control = rpart.control(minsplit =5, minbucket = 5,xval=5,cp = cvmin,maxdepth = 10),
data=df_imdb, method="class")
pred = predict(tree, type="class")
tree.conf = table(pred, df_imdb$gross_x3)
tree.conf
set.seed(1)
bag = randomForest(gross_x3 ~ . - gross_x3, data = df_imdb, mtry = length(df_imdb)-1, ntree = 500)
# results
knitr::kable(bag$confusion)
95/(2256+95)
table(df_imdb$gross_x3)
# results
knitr::kable(t(bag$confusion))
set.seed(1)
tree = rpart(gross_x3 ~ . - gross_x3,
control = rpart.control(minsplit =5, minbucket = 5,xval=5,cp = cvmin,maxdepth = 10),
data=df_imdb, method="class")
pred = predict(tree, type="class")
tree.conf = table(df_imdb$gross_x3,pred)
tree.conf.error = c(tree.conf[1,2]/(tree.conf[1,1]+tree.conf[1,2]),tree.conf[2,1]/(tree.conf[2,1]+tree.conf[2,2]))
tree.conf = cbind(tree.conf,tree.conf.error) # attach confusion error
colnames(tree.conf)[3] = 'class.error'
knitr::kable(tree.conf)
knitr::kable(tree.conf)
# results
knitr::kable(bag$confusion)
set.seed(1)
tree = rpart(gross_x3 ~ . - gross_x3,
control = rpart.control(minsplit =5, minbucket = 5,xval=5,cp = cvmin,maxdepth = 10),
data=df_imdb, method="class")
pred = predict(tree, type="class")
tree.conf = table(df_imdb$gross_x3,pred)
tree.conf.error = c(tree.conf[1,2]/(tree.conf[1,1]+tree.conf[1,2]),tree.conf[2,1]/(tree.conf[2,1]+tree.conf[2,2]))
tree.conf = cbind(tree.conf,tree.conf.error) # attach confusion error
colnames(tree.conf) = c('pred 0','pred 1' ,'class.error')
knitr::kable(tree.conf)
# Single tree - cp = 0.006 --> cross validated parameter
set.seed(1)
tree = rpart(gross_x3 ~ . - gross_x3,
control = rpart.control(minsplit =5, minbucket = 5,xval=5,cp = cvmin,maxdepth = 10),
data=df_imdb, method="class")
pred = predict(tree, type="class")
tree.conf = table(df_imdb$gross_x3,pred)
tree.conf.error = c(tree.conf[1,2]/(tree.conf[1,1]+tree.conf[1,2]),tree.conf[2,1]/(tree.conf[2,1]+tree.conf[2,2]))
tree.conf = cbind(tree.conf,tree.conf.error) # attach confusion error
colnames(tree.conf) = c('pred 0','pred 1' ,'class.error')
rownames(tree.conf) = c('obs 0','obs 1' )
knitr::kable(tree.conf)
colnames(bag$confusion) = c('pred 0','pred 1' ,'class.error')
rownames(bag$confusion) = c('obs 0','obs 1' )
knitr::kable(bag$confusion)
plot(bag, lwd = 2)
varImpPlot(bag)
# plot(bag, lwd = 2)
varImpPlot(bag)
install.packages("pander")
plot(df_imdb$budget_2015,df_imdb$gross_2015)
abline(a=0,b=3)
githubURL = "https://github.com/jakob-ra/Supervised-Machine-Learning/raw/master/HW5/imdb.RData"
load(url(githubURL))
#!!!! why / how set wd to git? to load data work
# Orig dataset
colnames(imdb)
sapply(imdb,class) # Checking classes of predictors
# Selecting relevant subset
df_imdb <- imdb[!is.na(imdb$budget_2015),] # drop missing budget
df_imdb <- df_imdb[!is.na(df_imdb$mpaa_rating),] # drop missing MPAA
df_imdb <- df_imdb[!is.na(df_imdb$gross_2015),] # Remove obs with missing values
df_imdb <- df_imdb[(df_imdb[,15]>=1000000),]# Select movies only budget at least 1m
# Make use of title: title length
df_imdb$title_length <- as.numeric(nchar(as.character(df_imdb$title)))
titles = df_imdb$title
# drop post screen variables
dropvars = c('imdb_score','gross', 'budget','user_reviews','critic_reviews','director','actors','title','year')
dropind = colnames(df_imdb)%in%dropvars
df_imdb <- df_imdb[,!dropind] # dropping
# create factor out of genre dummies
# outcome
df_imdb$gross_x3 <- as.factor(df_imdb$gross_2015 >= (df_imdb$budget_2015)*3) # 1 = movies gross box office takings of at least three times its budget
# Plot budget vs revenue, line with slope 3
plot(df_imdb$budget_2015,df_imdb$gross_2015)
abline(a=0,b=3)
plot(log(df_imdb$budget_2015),log(df_imdb$gross_2015))
plot(log(df_imdb$budget_2015),log(df_imdb$gross_2015))
xgrid = seq(0.1,4e8,length.out = 1000)
lines(log(xgrid),log(3*xgrid))
plot(log(df_imdb$budget_2015),log(df_imdb$gross_2015),
ylab = 'log gross',xlab='log budget')
xgrid = seq(0.1,4e8,length.out = 1000)
lines(log(xgrid),log(3*xgrid),col='red')
plot(log(df_imdb$budget_2015),log(df_imdb$gross_2015),
ylab = 'log gross',xlab='log budget')
xgrid = seq(0.1,4e8,length.out = 1000)
lines(log(xgrid),log(3*xgrid),col='red',lwd=2)
text(14,14,labels = 'gross = 3*budget',col='red')
plot(log(df_imdb$budget_2015),log(df_imdb$gross_2015),
ylab = 'log gross',xlab='log budget')
xgrid = seq(0.1,4e8,length.out = 1000)
lines(log(xgrid),log(3*xgrid),col='red',lwd=2)
text(14,14,labels = 'gross = 3*budget',col='red',pos = 4)
plot(log(df_imdb$budget_2015),log(df_imdb$gross_2015),
ylab = 'log gross',xlab='log budget')
xgrid = seq(0.1,4e8,length.out = 1000)
lines(log(xgrid),log(3*xgrid),col='red',lwd=2)
legend('bottomright',legend = 'gross = 3*budget',col='red',lwd = 2)
plot(baf,lwd=2)
plot(bag,lwd=2)
legend('right',legend = c('Class 0','Class 1','overall'),col=c('red','green','black'),lwd = c(2,1,3))
plot(bag,lwd=2,main = 'Classification error')
legend('right',legend = c('Class 0','Class 1','overall'),col=c('red','green','black'),lty= c(2,1,3))
plot(bag,lwd=2,main = 'Classification error')
legend('right',legend = c('Class 0','Class 1','overall'),col=c('red','green','black'),lty= c(2,3,1))
# TEST #
# Supervised Machine Learning - HW5 - #
# Maja Nordfeldt, Feb 2020 #
# -------------------------- Packages ---------------------------#
# rm(list = ls())
library(tidyverse)
library(partykit)
library(randomForest)
library("rpart")
library("rpart.plot")
# -------------------------- Data Preparation --------------------#
githubURL = "https://github.com/jakob-ra/Supervised-Machine-Learning/raw/master/HW5/imdb.RData"
load(url(githubURL))
#!!!! why / how set wd to git? to load data work
# Orig dataset
colnames(imdb)
sapply(imdb,class) # Checking classes of predictors
# Selecting relevant subset
df_imdb <- imdb[!is.na(imdb$budget_2015),] # drop missing budget
df_imdb <- df_imdb[!is.na(df_imdb$mpaa_rating),] # drop missing MPAA
df_imdb <- df_imdb[!is.na(df_imdb$gross_2015),] # Remove obs with missing values
df_imdb <- df_imdb[(df_imdb[,15]>=1000000),]# Select movies only budget at least 1m
# Make use of title: title length
df_imdb$title_length <- as.numeric(nchar(as.character(df_imdb$title)))
titles = df_imdb$title
# drop post screen variables
dropvars = c('imdb_score','gross', 'budget','user_reviews','critic_reviews','director','actors','title','year')
dropind = colnames(df_imdb)%in%dropvars
df_imdb <- df_imdb[,!dropind] # dropping
# create factor out of genre dummies
# outcome
df_imdb$gross_x3 <- as.factor(df_imdb$gross_2015 >= (df_imdb$budget_2015)*3) # 1 = movies gross box office takings of at least three times its budget
# Plot budget vs revenue, line with slope 3
plot(df_imdb$budget_2015,df_imdb$gross_2015)
abline(a=0,b=3)
plot(log(df_imdb$budget_2015),log(df_imdb$gross_2015),
ylab = 'log gross',xlab='log budget')
xgrid = seq(0.1,4e8,length.out = 1000)
lines(log(xgrid),log(3*xgrid),col='red',lwd=2)
legend('bottomright',legend = 'gross = 3*budget',col='red',lwd = 2)
df_imdb = subset(df_imdb, select = -gross_2015) # drop gross asa  predictor
# Missing values
summary(is.na(df_imdb))
# Analyse data imbalance
summary(df_imdb$gross_x3)
# ------------------ Package results for reference --------------------#
# small tree for visual explanation
treesmall = rpart(gross_x3 ~ . - gross_x3 -mpaa_rating,
control = rpart.control(minsplit =5, minbucket = 5,xval=5,cp = 0.004,maxdepth = 3),
data=df_imdb, method="class")
plot(as.party(treesmall))
# Single tree - cp = 1e-7 to get nice cp plot
set.seed(1)
tree = rpart(gross_x3 ~ . - gross_x3,
control = rpart.control(minsplit =5, minbucket = 5,xval=10,cp = 1e-7,maxdepth = 10),
data=df_imdb, method="class")
plotcp(tree)# 	plot cross-validation results
cpprint = printcp(tree)
cvmin = cpprint[which.min(cpprint[,4]),1]
cat('best cp:',cvmin,'\n')
cat('min xerror =:',cpprint[which.min(cpprint[,4]),4],'\n')
# Single tree - cp = 0.006 --> cross validated parameter
set.seed(1)
tree = rpart(gross_x3 ~ . - gross_x3,
control = rpart.control(minsplit =5, minbucket = 5,xval=5,cp = cvmin,maxdepth = 10),
data=df_imdb, method="class")
pred = predict(tree, type="class")
tree.conf = table(df_imdb$gross_x3,pred)
tree.conf.error = c(tree.conf[1,2]/(tree.conf[1,1]+tree.conf[1,2]),tree.conf[2,1]/(tree.conf[2,1]+tree.conf[2,2]))
tree.conf = cbind(tree.conf,tree.conf.error) # attach confusion error
colnames(tree.conf) = c('pred 0','pred 1' ,'class.error')
rownames(tree.conf) = c('obs 0','obs 1' )
knitr::kable(tree.conf)
library(pander)
pander(c(' ' ='mean',Budget=round(mean(df_imdb$budget_2015)),Revenue=round(mean(df_imdb$gross_2015)),
'Cast-FB-likes'=round(mean(df_imdb$cast_facebook_likes)),'Director-FB-likes'=round(mean(df_imdb$director_facebook_likes)),
Duration=round(mean(df_imdb$duration))),
caption = "Mean statistics of main variables")
knitr::opts_chunk$set(echo = F)
# TEST #
# Supervised Machine Learning - HW5 - #
# Maja Nordfeldt, Feb 2020 #
# -------------------------- Packages ---------------------------#
# rm(list = ls())
library(tidyverse)
library(partykit)
library(randomForest)
library("rpart")
library("rpart.plot")
# -------------------------- Data Preparation --------------------#
githubURL = "https://github.com/jakob-ra/Supervised-Machine-Learning/raw/master/HW5/imdb.RData"
load(url(githubURL))
#!!!! why / how set wd to git? to load data work
# Orig dataset
colnames(imdb)
sapply(imdb,class) # Checking classes of predictors
# Selecting relevant subset
df_imdb <- imdb[!is.na(imdb$budget_2015),] # drop missing budget
df_imdb <- df_imdb[!is.na(df_imdb$mpaa_rating),] # drop missing MPAA
df_imdb <- df_imdb[!is.na(df_imdb$gross_2015),] # Remove obs with missing values
df_imdb <- df_imdb[(df_imdb[,15]>=1000000),]# Select movies only budget at least 1m
# Make use of title: title length
df_imdb$title_length <- as.numeric(nchar(as.character(df_imdb$title)))
titles = df_imdb$title
# drop post screen variables
dropvars = c('imdb_score','gross', 'budget','user_reviews','critic_reviews','director','actors','title','year')
dropind = colnames(df_imdb)%in%dropvars
df_imdb <- df_imdb[,!dropind] # dropping
# create factor out of genre dummies
# outcome
df_imdb$gross_x3 <- as.factor(df_imdb$gross_2015 >= (df_imdb$budget_2015)*3) # 1 = movies gross box office takings of at least three times its budget
# Plot budget vs revenue, line with slope 3
plot(df_imdb$budget_2015,df_imdb$gross_2015)
abline(a=0,b=3)
plot(log(df_imdb$budget_2015),log(df_imdb$gross_2015),
ylab = 'log gross',xlab='log budget')
xgrid = seq(0.1,4e8,length.out = 1000)
lines(log(xgrid),log(3*xgrid),col='red',lwd=2)
legend('bottomright',legend = 'gross = 3*budget',col='red',lwd = 2)
knitr::include_graphics('./datavisual.pdf')
library(pander)
pander(c(' ' ='mean',Budget=round(mean(df_imdb$budget_2015)),Revenue=round(mean(df_imdb$gross_2015)),
'Cast-FB-likes'=round(mean(df_imdb$cast_facebook_likes)),'Director-FB-likes'=round(mean(df_imdb$director_facebook_likes)),
Duration=round(mean(df_imdb$duration))),
caption = "Mean statistics of main variables")
df_imdb = subset(df_imdb, select = -gross_2015) # drop gross asa  predictor
# Missing values
summary(is.na(df_imdb))
# Analyse data imbalance
summary(df_imdb$gross_x3)
knitr::opts_chunk$set(echo = F)
# TEST #
# Supervised Machine Learning - HW5 - #
# Maja Nordfeldt, Feb 2020 #
# -------------------------- Packages ---------------------------#
# rm(list = ls())
library(tidyverse)
library(partykit)
library(randomForest)
library("rpart")
library("rpart.plot")
# -------------------------- Data Preparation --------------------#
githubURL = "https://github.com/jakob-ra/Supervised-Machine-Learning/raw/master/HW5/imdb.RData"
load(url(githubURL))
#!!!! why / how set wd to git? to load data work
# Orig dataset
colnames(imdb)
sapply(imdb,class) # Checking classes of predictors
# Selecting relevant subset
df_imdb <- imdb[!is.na(imdb$budget_2015),] # drop missing budget
df_imdb <- df_imdb[!is.na(df_imdb$mpaa_rating),] # drop missing MPAA
df_imdb <- df_imdb[!is.na(df_imdb$gross_2015),] # Remove obs with missing values
df_imdb <- df_imdb[(df_imdb[,15]>=1000000),]# Select movies only budget at least 1m
# Make use of title: title length
df_imdb$title_length <- as.numeric(nchar(as.character(df_imdb$title)))
titles = df_imdb$title
# drop post screen variables
dropvars = c('imdb_score','gross', 'budget','user_reviews','critic_reviews','director','actors','title','year')
dropind = colnames(df_imdb)%in%dropvars
df_imdb <- df_imdb[,!dropind] # dropping
# create factor out of genre dummies
# outcome
df_imdb$gross_x3 <- as.factor(df_imdb$gross_2015 >= (df_imdb$budget_2015)*3) # 1 = movies gross box office takings of at least three times its budget
# Plot budget vs revenue, line with slope 3
plot(df_imdb$budget_2015,df_imdb$gross_2015)
abline(a=0,b=3)
plot(log(df_imdb$budget_2015),log(df_imdb$gross_2015),
ylab = 'log gross',xlab='log budget')
xgrid = seq(0.1,4e8,length.out = 1000)
lines(log(xgrid),log(3*xgrid),col='red',lwd=2)
legend('bottomright',legend = 'gross = 3*budget',col='red',lwd = 2)
knitr::include_graphics('./datavisual.pdf')
library(pander)
pander(c(' ' ='mean',Budget=round(mean(df_imdb$budget_2015)),Revenue=round(mean(df_imdb$gross_2015)),
'Cast-FB-likes'=round(mean(df_imdb$cast_facebook_likes)),'Director-FB-likes'=round(mean(df_imdb$director_facebook_likes)),
Duration=round(mean(df_imdb$duration))),
caption = "Mean statistics of main variables")
df_imdb = subset(df_imdb, select = -gross_2015) # drop gross asa  predictor
# Missing values
# summary(is.na(df_imdb))
#
# # Analyse data imbalance
# summary(df_imdb$gross_x3)
# ------------------ Package results for reference --------------------#
# small tree for visual explanation
treesmall = rpart(gross_x3 ~ . - gross_x3 -mpaa_rating,
control = rpart.control(minsplit =5, minbucket = 5,xval=5,cp = 0.004,maxdepth = 3),
data=df_imdb, method="class")
plot(as.party(treesmall))
# Single tree - cp = 1e-7 to get nice cp plot
set.seed(1)
tree = rpart(gross_x3 ~ . - gross_x3,
control = rpart.control(minsplit =5, minbucket = 5,xval=10,cp = 1e-7,maxdepth = 10),
data=df_imdb, method="class")
plotcp(tree)# 	plot cross-validation results
cpprint = printcp(tree)
cvmin = cpprint[which.min(cpprint[,4]),1]
cat('best cp:',cvmin,'\n')
cat('min xerror =:',cpprint[which.min(cpprint[,4]),4],'\n')
# Single tree - cp = 0.006 --> cross validated parameter
set.seed(1)
tree = rpart(gross_x3 ~ . - gross_x3,
control = rpart.control(minsplit =5, minbucket = 5,xval=5,cp = cvmin,maxdepth = 10),
data=df_imdb, method="class")
pred = predict(tree, type="class")
tree.conf = table(df_imdb$gross_x3,pred)
tree.conf.error = c(tree.conf[1,2]/(tree.conf[1,1]+tree.conf[1,2]),tree.conf[2,1]/(tree.conf[2,1]+tree.conf[2,2]))
tree.conf = cbind(tree.conf,tree.conf.error) # attach confusion error
colnames(tree.conf) = c('pred 0','pred 1' ,'class.error')
rownames(tree.conf) = c('obs 0','obs 1' )
knitr::kable(tree.conf)
# plot the tree
plot(as.party(tree))
tree$splits
prp(tree)
knitr::include_graphics('./bigtree.png')
set.seed(1)
bag = randomForest(gross_x3 ~ . - gross_x3, data = df_imdb, mtry = length(df_imdb)-1, ntree = 500)
# results
colnames(bag$confusion) = c('pred 0','pred 1' ,'class.error')
rownames(bag$confusion) = c('obs 0','obs 1' )
knitr::kable(bag$confusion)
varImpPlot(bag)
plot(bag,lwd=2,main = 'Classification error')
legend('right',legend = c('Class 0','Class 1','overall'),col=c('red','green','black'),lty= c(2,3,1))
par(mfrow=c(1,2))
varImpPlot(bag)
plot(bag,lwd=2,main = 'Classification error')
legend('right',legend = c('Class 0','Class 1','overall'),col=c('red','green','black'),lty= c(2,3,1))
set.seed(1)
bag = randomForest(gross_x3 ~ . - gross_x3, data = df_imdb, mtry = length(df_imdb)-1, ntree = 500)
knitr::kable(bag$confusion)
knitr::kable(bag$confusion)
par(mfrow=c(1,2))
varImpPlot(bag)
plot(bag,lwd=2,main = 'Classification error')
legend('right',legend = c('Class 0','Class 1','overall'),col=c('red','green','black'),lty= c(2,3,1))
