---
title: "Supervised Machine Learning HW 5"
author: "Group 3: Maja Nordfeldt, Jakob Rauch, Timo Schenk, Konstantin Sommer"
date: "25-1-2020"
output:
  pdf_document:
      fig_caption: yes
  html_notebook: default
---

# Introduction
Is it possible to before its screening predict whether a movie will be a blockbuster, only based on publicly available information? This question can be of high relevance for movie producers or producing companies that face the issue of how to optimally plan a movies market rollout, as well as assess the prospects of their future outcome. For example if one can predict that a movie is likely to be a huge sucess one might try to push it in more countries than only in the local one and might even increase marketing budgets in order to gain the full potential out of the success. Another stakeholder that might be interested are movie theaters that might base their scheduling (room size, screening times etc.) on it.
We will analyze this question from a very neutral perspective, without even assessing the movie quality, but only the information that is publicly available before a movie start, which might also be the information that decission makers will base their decission on, especially if they are outside of the production itself (like movie theaters). 


# Data
In order to answer our proposed question of how to predict a movie success we are using a sample out of data published by the Internet Movie Database (IMDb) that is publicly available for download. IMDb is an online database, in which users can not only view information about movies and acters/actresses but can also rank the movies.
The available datasets comprises information on movie names, director and actors as well as on the used budget and the assigned genre of the movie. We define a movie as being successfull if it manages to gain more than three times in box gross revenue than the available budget in the movie production. Box gross revenue is the income a movie gains from movie theater screenings. For both measures we are using inflation corrected numbers in 2015 dollars and define $gross_{x3}$ to be TRUE if the movie was successfull acoording to our criterium.
We exclude the names of the participating actors due to the otherwise extensive number of categorical variables but use the number of Facebook likes of the main actors as a proxy for the popularity of the cast and do the same for the director of the movie. We exlude reviews from critics and IMDb users, since they are likely to only be available after the start of the movie. We nevertheless include the MPAA rating that gives a recommondation on the age of the targeted audience that should be allowed to watch it since one can expect that this might have an influence on the success of a movie. The rating system is giving recommondations from suggested for the general audience to only suggested for people above the age of 17. We drop the year variable since it should be without interest for decission makers since they can not influence the timing of the movie release or put differently it is without interest to know if movies were especially succesfull in a certain year. We addtionally include 0 or 1 dummies for all genres, since movies can also fall into several of the categories. We also include the lenght of the title since one can assume that short titles might be catchier and therefore more succesfull. Finally we also inlcude the movie budget but exclude all movies with a budget below one million dollar.
A first insepction of the data shows that their are missing values in some of the observations, which we will drop in our manual estimation. Another important feature of the data is its unbalancendness. Looking at FIGURE XYZ in which we plot the movie budget versus the movie success one can see that there is a large amount of movies that do not make the threshold and only very few (about one fifth) that are categorized as successful. One can also see that there is only a few very expensive movies while most movies are in the bottom of the budget range.
###DO THE PLOT HERE AUB

```{r,echo=F, message=F, tab.lp="tab:1"}
library(pander) 
pander(c(' ' ='mean',Budget=round(mean(df_imdb$budget_2015)),Revenue=round(mean(df_imdb$gross_2015)),
         'Cast-FB-likes'=round(mean(df_imdb$cast_facebook_likes)),'Director-FB-likes'=round(mean(df_imdb$director_facebook_likes)),
         Duration=round(mean(df_imdb$duration))),
       caption = "Mean statistics of main variables")

```
In table \ref(tab:1) one can see the mean of our main variables of interest, excluding the genre dummies. One can see that the average movie budget is 51 million 2015-US dollar, the average facebook likes of the cast are 12 thousand and the avergae duration is 110 minutes, so 20 minutes more than the standard 90 minutes movie framework.
# Method
In order to assess the financial success of a proposed movie we adopt a classification tree and bagging approach respectively.

- run package ´rpart':
  - cp = 0.004 as in slides

- run package "randomForest":
- plot of out of bag error and number of bags/trees ---> tradeoff computations and error - we choose XXX no of trees for low error and fast computation




# Results

# Conclusion & Discussion

In this study, we asked the question whether we could predict whether a produced movie would return three times its budget before the start of its screening. Using binary classification, as well as bagging we found that it is indeed possible. 

XXX discussion of results XXXX

From a perspective of practice implementation the classification tree is intuitive and easy to interpret, which may be a benefit if to be used for convincing stakeholders and making collective decisions in an organization. We can further clearly follow the steps behind the outcome, more transparent than the “black-box” results of some other methods. Data preparation needed is also sparse - variable standardization is not needed, missing values are treated robustly and dummies are not necessarily required for categorical variables. One also does not need to perform feature selection as it is done implicitly, and interactions and non-linearity is handled. On the downside, the results may not be robust - minor changes to training data can alter tree and final predictions, and overfitting can be a serious problem. The usefulness of predictions in practice can therefore come into question and results are sensitive to the quality of data. 

The bagged approach help reduce variance of the traditional classification tree, and out of bag estimates are easy to use for validation. Although we still have easily interpretable diagnostics like the Gini index, contrasting the classification tree we now lack the intuitive visual interpretation. We have not included an extremely large number of trees to spare computation, increasing it would however increase the likelihood of their errors to cancel out, although gains are likely small. Keeping all features for trees rather than randomly selecting some means we introduce more correlation between trees, and although we could obtain lower errors this way it may also lead to overfitting. 

For future research, one might want to repeat the exercise with measures to compensate for the unbalanced dataset, eg with a balanced bootstrapping algorithm. Further, one could try with more formally optimized parameters (e.g. number of trees in the bagging or number of levels in classification tree). The data is also possibly biased, likely only applying to the time and place of the observations, why the analysis could be redone with a another (more) representative training sample. 





# Code
```{r ref.label=knitr::all_labels(), echo = T, eval = F}
```
